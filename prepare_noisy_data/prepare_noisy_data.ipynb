{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ac692-0bf9-47ad-a30e-cf9018a33620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2135a-bbff-47e5-984f-e389187a05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3ff51-9980-40f4-906f-b5482c3c972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3967124-d72a-41b8-b415-4420be5f9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input path of the data to make the noisy data from.\n",
    "ip_path = ''\n",
    "\n",
    "#Provide the path where you want to store the noisy data.\n",
    "op_path_del_gen = \"\"\n",
    "op_path_rep_gen = \"\"\n",
    "op_path_del_polr = \"\"\n",
    "op_path_rep_polr = \"\"\n",
    "\n",
    "gen_prob = # <please provide the probability> #0.1\n",
    "polr_prob = # <please provide the probability> #0.8\n",
    "#permu_change = 3\n",
    "\n",
    "\n",
    "src_df = pd.read_csv('trns_polr_dict/amzn_style/trns_polr_src.csv')\n",
    "src_dict = pd.Series(src_df.is_polarize.values,index=src_df.german_tokens).to_dict()\n",
    "# trg_df = pd.read_csv('trns_polr_dict/wmt/trns_polr_trg.csv')\n",
    "# trg_dict = pd.Series(trg_df.is_polarize.values,index=trg_df.english_tokens).to_dict()\n",
    "del(src_df)\n",
    "#del(trg_df)\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "SRC = Field(tokenize = tokenize_de,\n",
    "                lower = True,\n",
    "                batch_first = True,\n",
    "                fix_length=100)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en,\n",
    "            lower = True,\n",
    "            batch_first = True,\n",
    "            fix_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b9ded-e8bf-45ba-9dd7-c2016cd2897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_text_read(ip_path):\n",
    "    data = TranslationDataset(\n",
    "        path=ip_path,\n",
    "        exts=('.de', '.en'),\n",
    "        fields=(SRC, TRG),\n",
    "    )\n",
    "    print(f\"Path: {ip_path}, Number of examples: {len(data.examples)}\", flush=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8931da-b953-48cb-af88-854b9c5aa824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_gen_token_randomly(tokens, prob):\n",
    "    results = [token for token in tokens if not random.random() < prob]\n",
    "    return \" \".join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f6a50-df4d-49e9-aab8-666ce56d2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_gen_token_randomly(tokens, prob, filler='<style>'):\n",
    "    tokens_copy = tokens[:]\n",
    "    for idx in range(len(tokens_copy)):\n",
    "        if random.random() < prob:\n",
    "            tokens_copy[idx] = filler\n",
    "    return \" \".join(tokens_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a71b9-d9af-40dd-ba9c-cb548ca0a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_polr_token_randomly(tokens, prob, dct):\n",
    "    results = [token for token in tokens if not random.random() < prob and dct.get(token, False)== True]\n",
    "    return \" \".join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e06c7-e345-4ee7-9c7d-46c13330adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_polr_token_randomly(tokens, prob, dct, filler='<style>'):\n",
    "    tokens_copy = tokens[:]\n",
    "    for idx in range(len(tokens_copy)):\n",
    "        if random.random() < prob and dct.get(tokens_copy[idx], False)== True:\n",
    "            tokens_copy[idx] = filler\n",
    "    return \" \".join(tokens_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e61524-4773-4ead-a174-8e9da6f26478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_token_permutation(tokens, permu_range):\n",
    "#     new_indices = [i+random.uniform(0, permu_range+1) for i in range(len(tokens))]\n",
    "#     res = [x for _, x in sorted(zip(new_indices, tokens), key=lambda pair: pair[0])]\n",
    "#     return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cba1e2-2473-4628-bc78-98e2945fc66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pytorch_text_read(ip_path)\n",
    "for i in range(50):\n",
    "    with open(op_path_del_gen+str(i)+\".de\", 'w') as op_del_gen, \\\n",
    "            open(op_path_rep_gen+str(i)+\".de\", 'w') as op_rep_gen, \\\n",
    "            open(op_path_del_polr+str(i)+\".de\", 'w') as op_del_polr, \\\n",
    "            open(op_path_rep_polr+str(i)+\".de\", 'w') as op_rep_polr:\n",
    "\n",
    "            for idx in range(len(data.examples)):\n",
    "                de = vars(data.examples[idx])['src']\n",
    "                #en = vars(data.examples[idx])['trg']\n",
    "\n",
    "                del_tokens = del_gen_token_randomly(de, gen_prob)\n",
    "                if(del_tokens == ''):\n",
    "                    del_tokens = \" \".join(de)\n",
    "                op_del_gen.write(del_tokens + '\\n')\n",
    "\n",
    "                rep_tokens = rep_gen_token_randomly(de, gen_prob)\n",
    "                op_rep_gen.write(rep_tokens + '\\n')\n",
    "\n",
    "                del_polr_tokens = del_polr_token_randomly(de, polr_prob, src_dict)\n",
    "                if (del_polr_tokens == ''):\n",
    "                    del_polr_tokens = \" \".join(de)\n",
    "                op_del_polr.write(del_polr_tokens + '\\n')\n",
    "\n",
    "                rep_polr_tokens = rep_polr_token_randomly(de, polr_prob, src_dict)\n",
    "                op_rep_polr.write(rep_polr_tokens + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
